{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1c7d5b62",
   "metadata": {},
   "source": [
    "# biased_sgd: expertiments reproduction\n",
    "\n",
    "Tested on MacOS and Linux"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fcb7dcf",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-25T00:00:40.676173Z",
     "start_time": "2023-04-25T00:00:37.324603Z"
    }
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import numpy as np\n",
    "import time\n",
    "import sys\n",
    "import os\n",
    "import argparse\n",
    "from numpy.linalg import norm\n",
    "import itertools\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "import math\n",
    "import datetime\n",
    "from IPython import display\n",
    "\n",
    "from contextlib import redirect_stdout\n",
    "import shutil\n",
    "import subprocess\n",
    "import matplotlib.ticker as tck\n",
    "\n",
    "import matplotlib.colors as mcolors\n",
    "import matplotlib.markers as mmarkers\n",
    "\n",
    "intrepr = lambda x: int(x) if x.is_integer() else round(x,8)\n",
    "myrepr = lambda x: repr(round(x, 8)).replace('.',',') if isinstance(x, float) else repr(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dab551ca-092b-4c95-98ae-7a00de1149d3",
   "metadata": {},
   "source": [
    "## Datasets preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ca3763b-a20f-4337-92f8-cc94013e27a9",
   "metadata": {},
   "source": [
    "The next cell creates bash script that launches a necessary dataset preprocessing that is required before launching experients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abfe04b1-45af-4c90-ac40-7de278670043",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile preprocess_datasets.sh\n",
    "#!/bin/bash\n",
    "\n",
    "datasets=(\"splice\" \"a9a\" \"w8a\")\n",
    "loss_func=\"log-reg\"\n",
    "la=\"1\"\n",
    "\n",
    "for dataset in \"${datasets[@]}\"; do\n",
    "    echo \"Running script for dataset: ${dataset} with --la: ${la}\"\n",
    "    python3 b_sgd_data_preprocessing.py --dataset \"${dataset}\" --loss_func \"${loss_func}\" --la \"${la}\"\n",
    "done\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8df2ecf-28f8-4cfc-ba4f-aaf12d292034",
   "metadata": {},
   "outputs": [],
   "source": [
    "!cat preprocess_datasets.sh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9207c42-ae77-4c77-b651-823ce156ded2",
   "metadata": {},
   "outputs": [],
   "source": [
    "!bash preprocess_datasets.sh"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "792053a7-9938-42e6-9229-33dbb5622a81",
   "metadata": {},
   "source": [
    "## Run experiments"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19d8ac3f-5fe3-4411-914b-450c64ad981d",
   "metadata": {},
   "source": [
    "The next cell creates bash script that launches experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ea61bdf-1039-4ae8-a164-2a01c066170f",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile experiments_run.sh\n",
    "#!/bin/bash\n",
    "\n",
    "datasets=(\"splice\" \"a9a\" \"w8a\")\n",
    "la_values=(\"1.0\")\n",
    "prb_values=(\"0.01\" \"0.1\" \"0.5\")\n",
    "\n",
    "\n",
    "setting_type=\"biased\"\n",
    "prb_type=\"uniform\"\n",
    "factor=1\n",
    "importance_normed_probs=0\n",
    "\n",
    "max_comms=5000\n",
    "max_epochs=5000\n",
    "tol=1e-10\n",
    "\n",
    "datasets_length=${#datasets[@]}\n",
    "la_length=${#la_values[@]}\n",
    "prb_length=${#prb_values[@]}\n",
    "product_length=$((datasets_length * la_length * prb_length))\n",
    "echo \"Number of scripts to launch: $product_length\"\n",
    "\n",
    "for dataset in \"${datasets[@]}\"; do\n",
    "  for la in \"${la_values[@]}\"; do\n",
    "    for prb in \"${prb_values[@]}\"; do\n",
    "      python3 sgd-ind.py --factor $factor --tol $tol --dataset $dataset --prb $prb --prb_type $prb_type --setting_type $setting_type --max_epochs $max_epochs --max_comms $max_comms --la \"${la}\" --importance_normed_probs $importance_normed_probs\n",
    "    done\n",
    "  done\n",
    "done\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8803f07e-cb40-4e42-a19e-ab366f3340f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "!cat experiments_run.sh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99460edc-2ac4-4b98-91b2-67230692a5c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "!bash experiments_run.sh"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16ebe2c7-5f43-4a8f-abc1-3a976e37d1cf",
   "metadata": {},
   "source": [
    "## Draw plots"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3410583-a171-4692-b7d8-5708a9185ed8",
   "metadata": {},
   "source": [
    "The next cell draw plots and saves an output as vector image in the folder \"plot_all-datasets\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bddb1ab6-f5f8-4268-8551-a346f99c4942",
   "metadata": {},
   "outputs": [],
   "source": [
    "def iter_to_bits(num_iters, k_ar,  size_value):\n",
    "    return (num_iters, int (size_value*num_iters*np.max(k_ar)))\n",
    "\n",
    "def bits_to_iter(num_bits, k_ar,  size_value):\n",
    "    return (int (num_bits/(size_value*np.min(k_ar))), num_bits )\n",
    "\n",
    "def fix_shape(np_array):\n",
    "    if len (np_array.shape)==2:\n",
    "        if np_array.shape[0]==1:\n",
    "            np_array = np_array.flatten()\n",
    "        else: \n",
    "            raise ValueError(\"wrong shape\")\n",
    "    return np_array\n",
    "def load_np_array (path_to_file, pickle=True):\n",
    "    try:\n",
    "        np_array = np.load(path_to_file, allow_pickle=pickle)\n",
    "        #its = np.load(logs_file_its)\n",
    "    except IOError:\n",
    "        print (path_to_file+\": its failed to be loaded: IOError\")\n",
    "        np_array = np.array([-1])\n",
    "    return np_array\n",
    "def get_plot_path(save_separately, project_path, dataset):\n",
    "    if save_separately:\n",
    "        plot_path = project_path + \"plot_{0}/\".format(dataset)\n",
    "    else:\n",
    "        plot_path = project_path + \"plot_all-datasets/\"\n",
    "    return plot_path\n",
    "def get_ub_x(cut_axis, x_axis, s, else_value):\n",
    "    #do not use; not ready\n",
    "    if cut_axis:\n",
    "        ub_x = {'iteration_bits_od':{0.0:100_000, 0.2:100_000, 0.8:100_000, 1.6:100_000, 6.4:100_000, 12.8:100_000, 25.6:100_000}}[x_axis][s]\n",
    "    else:\n",
    "        ub_x = else_value\n",
    "    return ub_x\n",
    "\n",
    "def load_all_logs (experiment_ar, dataset, project_path, ub_x, x_axis, y_axis):\n",
    "    its_ar = []\n",
    "    grad_norms_ar= []\n",
    "    its_last_value = np.zeros(len(experiment_ar))\n",
    "    grad_norms_last_value = np.zeros(len(experiment_ar))\n",
    "    is_ind_uploaded = np.zeros(len(experiment_ar), dtype=int)\n",
    "    for i, experiment in enumerate(experiment_ar):\n",
    "\n",
    "        logs_path = project_path + \"logs/logs_{0}_{1}/\".format(dataset, experiment)\n",
    "        logs_file_its = logs_path + x_axis + \"_\" + experiment + \".npy\"\n",
    "        logs_file_norms = logs_path + y_axis + '_' + experiment+'.npy'\n",
    "        if os.path.isfile(logs_file_its):\n",
    "            is_ind_uploaded[i] = 1\n",
    "            its = fix_shape(load_np_array(logs_file_its))          \n",
    "\n",
    "            number_its = len(its[its < ub_x])\n",
    "            its_ar.append(its[:number_its])\n",
    "            \n",
    "            norms = fix_shape(load_np_array(logs_file_norms)  )              \n",
    "            grad_norms_ar.append(norms[:number_its])\n",
    "            \n",
    "            #debug section\n",
    "            #np.save (logs_path + x_axis + \"_\" + experiment, np.arange(ub_x))\n",
    "            #np.save (logs_path + y_axis + \"_\" + experiment, norms[:ub_x])\n",
    "            \n",
    "        else:\n",
    "            is_ind_uploaded[i] = 0\n",
    "            its_ar.append(np.array([-1])) #emplhasising the error\n",
    "            grad_norms_ar.append(np.array([-1]))\n",
    "            print (logs_file_its + \" is not computed\")\n",
    "\n",
    "        grad_norms_last_value[i] = grad_norms_ar[-1][-1]\n",
    "        its_last_value[i] = its_ar[-1][-1]\n",
    "        if print_each_exp:\n",
    "            #print (\"%34s iter: %8d; norms: %9.2e;  bits/n: %8d;\"%(label_ar[i], its_ar[-1].shape[0], grad_norms_ar[-1][-1], its_ar[-1][-1] ) )\n",
    "            print (\"%d: %34s iter: %8d; %6s: %9.2e; %6s: %8d; grad_norms_shape: %8d; shapes_equality: %1d\"%(i, label_ar[i], its_ar[-1].shape[0], y_axis, grad_norms_ar[-1][-1], x_axis, its_ar[-1][-1], grad_norms_ar[-1].shape[0], grad_norms_ar[-1].shape[0]==its_ar[-1].shape[0]) )      \n",
    "    return its_ar, grad_norms_ar, its_last_value, grad_norms_last_value, is_ind_uploaded\n",
    "\n",
    "def get_min_params (grad_norms_last_value, its_last_value, is_ind_uploaded, print_min, dict_type_output, label_ar, its_ar, grad_norms_ar, tol, x_axis, y_axis):\n",
    "    if print_min:\n",
    "        grad_norms_last_value_m = grad_norms_last_value.copy()\n",
    "        its_last_value_m = its_last_value.copy()\n",
    "\n",
    "        non_loaded_inds = np.argwhere(is_ind_uploaded==0).flatten()\n",
    "        above_tol_inds =  np.argwhere( grad_norms_last_value_m[~np.isnan(grad_norms_last_value_m)] > tol).flatten()\n",
    "        inf_inds = np.argwhere(np.isinf(grad_norms_last_value_m)).flatten()\n",
    "        nan_inds = np.argwhere(np.isnan(grad_norms_last_value_m)).flatten()\n",
    "        upd_inds = np.unique (np.concatenate((non_loaded_inds, above_tol_inds, inf_inds, nan_inds)))\n",
    "\n",
    "        if minimize_over == \"grad_norms\":\n",
    "            grad_norms_last_value_m[upd_inds] = np.inf\n",
    "            it_min = np.argmin (grad_norms_last_value_m)\n",
    "        elif minimize_over == \"its\":\n",
    "            its_last_value_m[upd_inds] = np.inf\n",
    "            it_min = np.argmin (its_last_value_m)\n",
    "        else: \n",
    "            raise ValueError(\"wrong axis name\")\n",
    "\n",
    "        if dict_type_output:\n",
    "            print (label_ar[it_min])\n",
    "        else:\n",
    "            print (\"\\n %34s iter: %8d; %6s: %9.2e  %6s: %8d \\n\"%(label_ar[it_min], its_ar[it_min].shape[0], y_axis, grad_norms_ar[it_min][-1], x_axis, its_last_value[it_min]))\n",
    "            \n",
    "def get_nan_dataframes(experiment_ar, grad_norms_last_value,its_ar,grad_norms_ar, nan_investigate, df_generate):\n",
    "    if nan_investigate:\n",
    "        nan_inds = np.argwhere(np.isnan(grad_norms_last_value)).flatten()\n",
    "        if df_generate:\n",
    "            df_its_list = []\n",
    "            df_grad_norms_list = []\n",
    "            for i in nan_inds:\n",
    "                df_its_list.append(pd.DataFrame({experiment_ar[i]:its_ar[i]}))\n",
    "                df_grad_norms_list.append(pd.DataFrame({experiment_ar[i]:grad_norms_ar[i]}))\n",
    "            df_its = pd.concat(df_its_list, ignore_index=False, axis=1)\n",
    "            df_norms = pd.concat(df_grad_norms_list, ignore_index=False, axis=1)\n",
    "            return df_its, df_norms, nan_inds\n",
    "        else: \n",
    "            return pd.DataFrame(),pd.DataFrame(),nan_inds\n",
    "            \n",
    "    else:\n",
    "        return pd.DataFrame(),pd.DataFrame(), np.array([])\n",
    "\n",
    "\n",
    "\n",
    "def non_local_methods_params(setting_type_ar, prb_type_ar, prb_ar, factor_ar, la_ar):\n",
    "    return list(itertools.product (setting_type_ar, prb_type_ar, prb_ar, factor_ar, la_ar))\n",
    "\n",
    "def cut_logs_freq (its_ar, grad_norms_ar, freq):\n",
    "    cutted_its_ar = []\n",
    "    cutted_grad_norms_ar = []\n",
    "    for i in range(len(its_ar)):\n",
    "        mask = np.arange(start=0, stop=its_ar[i].shape[0], step=freq)\n",
    "        cutted_its_ar.append(its_ar[i][mask])\n",
    "        cutted_grad_norms_ar.append(grad_norms_ar[i][mask])\n",
    "    return cutted_its_ar, cutted_grad_norms_ar\n",
    "\n",
    "def draw_merged_plots(fig_ax_ar, plot_path, filename, x_label, plots_titles, y_label, save, legend_location, ymin=None, ymax=None, xlim=None):\n",
    "    size = 40\n",
    "    marker_size = 30\n",
    "    #plt.rcParams['font.family'] = 'serif'\n",
    "    #plt.rcParams['font.serif'] = 'FreeSerif'\n",
    "    plt.rcParams['lines.linewidth'] = 4\n",
    "    plt.rcParams['xtick.labelsize'] = size\n",
    "    plt.rcParams['ytick.labelsize'] = size\n",
    "    plt.rcParams['legend.fontsize'] = 30\n",
    "    plt.rcParams['axes.titlesize'] = size\n",
    "    plt.rcParams['axes.labelsize'] = size\n",
    "    plt.rcParams[\"figure.figsize\"] = [50,12]\n",
    "\n",
    "    (fig, axs) = fig_ax_ar\n",
    "    \n",
    "    for j in range(len(plots_titles)):\n",
    "        axs[j].set_xlabel(x_label, fontsize=size)\n",
    "        axs[j].set_ylabel(y_label, fontsize=size)\n",
    "        axs[j].set_title(f\"{plots_titles[j]}\", fontsize=30)\n",
    "        axs[j].set_yscale('log')\n",
    "\n",
    "        legend = axs[j].legend(loc=legend_location, framealpha=0.5)\n",
    "        axs[j].grid()\n",
    "\n",
    "        #x_min, x_max = np.min(axs[j].get_lines()[0].get_xdata()), np.max(axs[j].get_lines()[0].get_xdata())\n",
    "        #y_min, y_max = np.min(axs[j].get_lines()[0].get_ydata()), np.max(axs[j].get_lines()[0].get_ydata())\n",
    "\n",
    "        #axs[j].set_xlim(x_min*0.995, x_max*1.0001)\n",
    "        #axs[j].set_ylim(y_min*0.995, y_max*1.0001)\n",
    "        \n",
    "        #axs[j].set_xlim(x_min, x_max)\n",
    "        #axs[j].set_ylim(y_min, y_max)\n",
    "\n",
    "        axs[j].locator_params(axis='x', nbins=4)\n",
    "        #axs[j].locator_params(axis='y', numticks=10)\n",
    "        \n",
    "        #locmin = tck.LogLocator(base=10.0, subs=(0.1,0.2,0.3,0.4,0.5,0.6,0.7,0.8), numticks=10)\n",
    "        #axs[j].yaxis.set_minor_locator(locmin)\n",
    "        axs[j].yaxis.set_minor_formatter(tck.LogFormatter())\n",
    "        #axs[j].yaxis.set_minor_formatter(tck.FormatStrFormatter('%.2f'))\n",
    "\n",
    "\n",
    "    where = plot_path + \"_0_\" + filename\n",
    "    plt.show()\n",
    "    if save:\n",
    "        print(f\"saving to: {where}...\")\n",
    "        fig.savefig(plot_path + \"_0_\" + filename, bbox_inches='tight')\n",
    "        print(f\"saving is finished!\")\n",
    "\n",
    "\n",
    "project_path = os.getcwd() + \"/\"\n",
    "\n",
    "loss_func = \"log-reg\"\n",
    "dim_dict = {\"mushrooms\":112, \"w8a\":300, \"a9a\":123, \"realsim\":20958,\"splice\":60}\n",
    "dataset_size_dict = {\"mushrooms\": 8124, \"w8a\": 49749, \"a9a\": 32561, \"realsim\": 72309, \"splice\":1000}\n",
    "\n",
    "biased_tuning_factors_dict = {\"mushrooms\":[65536.0, 131072.0, 262144.0, 524288.0, 1048576.0],\n",
    "                              \"w8a\":[262144.0, 524288.0, 1048576.0],\n",
    "                              \"a9a\":[32768.0, 65536.0, 131072.0, 262144.0, 524288.0, 1048576.0]}\n",
    "\n",
    "optimal_biased_factors = {\"mushrooms\":[131072.0*2, 131072.0*4], \"w8a\":[1048576.0,1048576.0*2], \"a9a\":[131072.0*2,131072.0*4]}\n",
    "optimal_biased_factors = {\"mushrooms\":[131072.0*2], \"w8a\":[1048576.0], \"a9a\":[131072.0*4]} \n",
    "\n",
    "\n",
    "color_ar_1 = ['blue', 'orange','red', 'aqua', 'violet','cornflowerblue', 'darkgreen', 'coral', 'lime', 'darkgreen', 'goldenrod', 'maroon','black', 'brown', 'yellowgreen',\n",
    "              \"purple\", \"violet\", \"magenta\", \"green\",\"chocolate\",\"crimson\"]\n",
    "all_colors = mcolors.CSS4_COLORS\n",
    "remaining_colors = list(set(all_colors.keys()) - set(color_ar_1))\n",
    "color_ar_1.extend(remaining_colors)\n",
    "marker_ar = [\"o\", \"P\", \"v\", \"*\", \"<\", \">\", \"s\", \"p\", \"^\", \"h\", \"H\", \"+\", \"x\", \"X\", \"D\", \"d\", \"|\", \"_\",1,2,3,4,5,6,7,8,9]\n",
    "all_markers = list(mmarkers.MarkerStyle.markers.keys())\n",
    "remaining_markers = list(set(all_markers) - set(marker_ar))\n",
    "marker_ar.extend(remaining_markers)\n",
    "\n",
    "marker_size = 30\n",
    "y_axis = 'grad_norms'\n",
    "x_axis = 'comms'\n",
    "#x_axis = 'epochs'\n",
    "\n",
    "preset = \"unb_tuning\"\n",
    "#preset = \"b_tuning\"\n",
    "preset = \"biased_unbiased_comparison\"\n",
    "preset = \"b_uniform\"\n",
    "#preset = \"b_importance\"\n",
    "#preset = \"uniform_vs_importance\"\n",
    "    \n",
    "x_label = {'epochs':'Data passes','comms':'iterations' }[x_axis]\n",
    "y_label = {'grad_norms':r\"$\\||\\nabla f(x^k)\\||^2$\"}[y_axis]\n",
    "\n",
    "dataset_ar = [\"splice\", \"w8a\", \"a9a\"]\n",
    "\n",
    "exps = [\"sgd-ind\"]\n",
    "\n",
    "#prb_ar = [0.01]\n",
    "#prb = prb_ar[0]\n",
    "\n",
    "factor_ar = np.array([1], dtype=float)\n",
    "\n",
    "prb_ar = [0.01, 0.1, 0.5]\n",
    "la_ar = [1.0]\n",
    "\n",
    "main_title = preset\n",
    "\n",
    "#freq = int(1/(prb*10))\n",
    "freq = 1\n",
    "\n",
    "fig, axs = plt.subplots(1, len(dataset_ar))\n",
    "for (j,dataset) in enumerate(dataset_ar):\n",
    "    print (f\"dataset: {dataset}\")\n",
    "    list_param_tuples_dict = {}\n",
    "    exp_ar_dict = {\"sgd-ind\":[]}\n",
    "    label_ar_dict = exp_ar_dict.copy()     \n",
    "    \n",
    "    if \"sgd-ind\" in exps:\n",
    "        if preset == \"unb_tuning\":\n",
    "            list_param_tuples_dict[\"sgd-ind\"] = non_local_methods_params(['unbiased'],['uniform'],[0.01],[0.25,0.5,1.0,2.0,4.0,8.0 ]) \n",
    "        elif preset == \"b_tuning\":\n",
    "            factors = [32768.0, 65536.0, 131072.0, 262144.0, 524288.0, 1048576.0]\n",
    "            list_param_tuples_dict[\"sgd-ind\"] = non_local_methods_params(['biased'],['uniform'],[0.01], factors)\n",
    "        elif preset == \"biased_unbiased_comparison\":\n",
    "            factors = optimal_biased_factors[dataset]\n",
    "            list_param_tuples_dict[\"sgd-ind\"] = [('unbiased', 'uniform', 0.01, 1.0), ('biased', 'uniform', 0.01, 1.0), ('biased', 'uniform', 0.01, factors[0])]\n",
    "            #print(list_param_tuples_dict[\"sgd-ind\"])\n",
    "        elif preset == \"b_uniform\":\n",
    "            list_param_tuples_dict[\"sgd-ind\"] = [('biased', 'uniform', 0.01, 1.0, 1.0), ('biased', 'uniform', 0.1, 1.0, 1.0), ('biased', 'uniform', 0.5, 1.0, 1.0)]\n",
    "        elif preset == \"b_importance\":\n",
    "            list_param_tuples_dict[\"sgd-ind\"] = [('biased', 'importance', 0.01, 1.0, 1.0), ('biased', 'importance', 0.1, 1.0, 1.0), ('biased', 'importance', 0.5, 1.0, 1.0)]\n",
    "        elif preset == \"uniform_vs_importance\":\n",
    "            pass\n",
    "        else:\n",
    "            raise ValuError(\"wrong preset\")\n",
    "        \n",
    "\n",
    "    else:\n",
    "        raise ValueError(\"Wrong preset!\")\n",
    "        \n",
    "    \n",
    "    if \"sgd-ind\" in exps:\n",
    "        #exp_ar_dict[\"sgd-ind\"] = [\"sgd-ind_{0}_{1}_{2}_{3}x\".format(setting, prb_type, myrepr(prb), myrepr(factor)) for i, (setting, prb_type, prb, factor) in enumerate (list_param_tuples_dict[\"sgd-ind\"])]\n",
    "        #label_ar_dict[\"sgd-ind\"] = [\"SGD-{0}; {1}x\".format(setting, intrepr(factor)) for i, (setting, prb_type, prb, factor) in enumerate (list_param_tuples_dict[\"sgd-ind\"])]\n",
    "        \n",
    "        exp_ar_dict[\"sgd-ind\"] = [\"sgd-ind_{0}_{1}_{2}_{4}_{3}x\".format(setting, prb_type, myrepr(prb), myrepr(factor), myrepr(la)) for i, (setting, prb_type, prb, factor, la) in enumerate(list_param_tuples_dict[\"sgd-ind\"])]\n",
    "        label_ar_dict[\"sgd-ind\"] = [r\"p={2}\".format(setting, prb_type, prb, intrepr(factor), la) for i, (setting, prb_type, prb, factor, la) in enumerate(list_param_tuples_dict[\"sgd-ind\"])]\n",
    "\n",
    "    exp_keys, label_keys = list(exp_ar_dict.keys()),list(label_ar_dict.keys())\n",
    "    assert(set(exp_keys) == set(label_keys))\n",
    "    experiment_ar,label_ar = [],[] \n",
    "    for key in exp_keys:\n",
    "        experiment_ar += exp_ar_dict[key]    \n",
    "        label_ar += label_ar_dict[key]\n",
    "\n",
    "    ub_x = 5_000\n",
    "    tol = 1e+10\n",
    "\n",
    "    ########\n",
    "    draw = 1\n",
    "    save = 1          \n",
    "    save_separately = 0\n",
    "    print_each_exp = 0\n",
    "    cut_axis = 0\n",
    "    dict_type_output = 0\n",
    "    nan_investigate = 0\n",
    "    df_generate = 0\n",
    "    print_min = 0\n",
    "    minimize_over = \"grad_norms\"\n",
    "    #minimize_over = \"its\"\n",
    "    #assert ((not nan_investigate) or (not print_min))\n",
    "    #######\n",
    "    its_ar, grad_norms_ar, its_last_value, grad_norms_last_value, is_ind_uploaded = load_all_logs (experiment_ar, dataset, project_path, ub_x, x_axis, y_axis)\n",
    "    its_ar, grad_norms_ar = cut_logs_freq(its_ar, grad_norms_ar, freq)\n",
    "    get_min_params(grad_norms_last_value, its_last_value, is_ind_uploaded, print_min, dict_type_output, label_ar, its_ar, grad_norms_ar, tol, x_axis, y_axis)\n",
    "    df_its, df_norms, nan_inds = get_nan_dataframes(experiment_ar, grad_norms_last_value,its_ar,grad_norms_ar, nan_investigate, df_generate)\n",
    "    non_nan_inds = np.setdiff1d (np.arange(len(experiment_ar)), nan_inds)\n",
    "    non_nan_its_ar = [its_ar[i] for i in non_nan_inds]\n",
    "    non_nan_grad_norms_ar = [grad_norms_ar[i] for i in non_nan_inds]\n",
    "    non_nan_label_ar = [label_ar[i] for i in non_nan_inds]\n",
    "    \n",
    "    \n",
    "    for i in range (len(its_ar)):\n",
    "        x_shape = its_ar[i].shape[0]\n",
    "        y_shape = grad_norms_ar[i].shape[0]\n",
    "        if x_shape != y_shape:\n",
    "            min_shape =  min(x_shape, y_shape)\n",
    "            its_ar[i] = its_ar[i][:min_shape]\n",
    "            grad_norms_ar[i] = grad_norms_ar[i][:min_shape]\n",
    "        \n",
    "        inds = np.arange (its_ar[i].shape[0])\n",
    "        markers_on = inds[inds % (int(len(inds[:-(1 + 2 * i)]) / 10)) == 0].astype(int)\n",
    "        \n",
    "        #axs[j].plot(its_ar[i], grad_norms_ar[i], 'r', label=label_ar[i], color=color_dict[color_dict_keys[i]], marker=marker_dict[color_dict_keys[i]], markevery=list(markers_on), markersize=marker_size, markerfacecolor=color_dict[color_dict_keys[i]], markeredgecolor = 'black')\n",
    "        axs[j].plot(its_ar[i], grad_norms_ar[i], 'r', label=label_ar[i], color=color_ar_1[i], marker=marker_ar[i], markevery=list(markers_on), markersize=marker_size, markerfacecolor=color_ar_1[i], markeredgecolor = 'black')\n",
    "\n",
    "filename = \"{0}_{1}.pdf\".format(main_title, preset)\n",
    "plot_path = get_plot_path(save_separately, project_path, dataset)\n",
    "if not os.path.exists(plot_path):\n",
    "    os.makedirs(plot_path)\n",
    "\n",
    "dataset_titles = dataset_ar\n",
    "plots_titles = {\"unb_tuning\":[dataset+ \";\" + r\" ${E}[|{S}|]=$\"+f\"{dataset_size_dict[dataset]*prb_ar[0]}\"+ \"; \" + f\"uniform-{prb_ar[0]}\" for dataset in dataset_titles],\n",
    "    \"b_tuning\":[dataset+ \";\" + r\" ${E}[|{S}|]=$\"+f\"{dataset_size_dict[dataset]*prb_ar[0]}\"+ \"; \" + f\"uniform-{prb_ar[0]}\" for dataset in dataset_titles],\n",
    "    \"biased_unbiased_comparison\":[dataset+ \";\" + r\" ${E}[|{S}|]=$\"+f\"{dataset_size_dict[dataset]*prb_ar[0]}\"+ \"; \" + f\"uniform-{prb_ar[0]}\" for dataset in dataset_titles],\n",
    "    \"b_uniform\":[\"BiasedSGD-ind; \" + f\"dataset: {dataset}; sampling: uniform\" for dataset in dataset_titles],\n",
    "    \"b_importance\":[\"BiasedSGD-ind; \" + f\"dataset: {dataset};\" for dataset in dataset_titles],\n",
    "    \"uniform_vs_importance\":None   \n",
    "}[preset]\n",
    "legend_location =\"best\"\n",
    "fig_ax_ar = (fig, axs)\n",
    "bottom = 1e-5\n",
    "\n",
    "draw_merged_plots(fig_ax_ar, plot_path, filename, x_label, plots_titles, y_label, save, legend_location, ymin=bottom, ymax=None, xlim=None)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d52611da-44c3-4527-a2cd-f301ddc9b8cf",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
